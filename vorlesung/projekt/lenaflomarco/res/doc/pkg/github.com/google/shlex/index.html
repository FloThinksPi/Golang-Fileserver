<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="theme-color" content="#375EAB">

  <title>shlex - The Go Programming Language</title>

<link type="text/css" rel="stylesheet" href="../../../../lib/godoc/style.css">

<link rel="stylesheet" href="../../../../lib/godoc/jquery.treeview.css">
<script type="text/javascript">window.initFuncs = [];</script>
</head>
<body>

<div id='lowframe' style="position: fixed; bottom: 0; left: 0; height: 0; width: 100%; border-top: thin solid grey; background-color: white; overflow: auto;">
...
</div><!-- #lowframe -->

<div id="topbar" class="wide"><div class="container">
<div class="top-heading" id="heading-wide"><a href="http://localhost:9090/">The Go Programming Language</a></div>
<div class="top-heading" id="heading-narrow"><a href="http://localhost:9090/">Go</a></div>
<a href="index.html#" id="menu-button"><span id="menu-button-arrow">&#9661;</span></a>
<form method="GET" action="http://localhost:9090/search">
<div id="menu">
<a href="http://localhost:9090/doc/">Documents</a>
<a href="../../../index.html">Packages</a>
<a href="http://localhost:9090/project/">The Project</a>
<a href="http://localhost:9090/help/">Help</a>
<a href="http://localhost:9090/blog/">Blog</a>

<input type="text" id="search" name="q" class="inactive" value="Search" placeholder="Search">
</div>
</form>

</div></div>



<div id="page" class="wide">
<div class="container">


  <h1>Package shlex</h1>




<div id="nav"></div>


<!--
	Copyright 2009 The Go Authors. All rights reserved.
	Use of this source code is governed by a BSD-style
	license that can be found in the LICENSE file.
-->
<!--
	Note: Static (i.e., not template-generated) href and id
	attributes start with "pkg-" to make it impossible for
	them to conflict with generated attributes (some of which
	correspond to Go identifiers).
-->

	<script type='text/javascript'>
	document.ANALYSIS_DATA = null;
	document.CALLGRAPH = null;
	</script>

	
		
		<div id="short-nav">
			<dl>
			<dd><code>import "github.com/google/shlex"</code></dd>
			</dl>
			<dl>
			<dd><a href="index.html#pkg-overview" class="overviewLink">Overview</a></dd>
			<dd><a href="index.html#pkg-index" class="indexLink">Index</a></dd>
			
			
			</dl>
		</div>
		<!-- The package's Name is printed as title by the top-level template -->
		<div id="pkg-overview" class="toggleVisible">
			<div class="collapsed">
				<h2 class="toggleButton" title="Click to show Overview section">Overview ▹</h2>
			</div>
			<div class="expanded">
				<h2 class="toggleButton" title="Click to hide Overview section">Overview ▾</h2>
				<p>
Package shlex implements a simple lexer which splits input in to tokens using
shell-style rules for quoting and commenting.
</p>
<p>
The basic use case uses the default ASCII lexer to split a string into sub-strings:
</p>
<pre>shlex.Split(&#34;one \&#34;two three\&#34; four&#34;) -&gt; []string{&#34;one&#34;, &#34;two three&#34;, &#34;four&#34;}
</pre>
<p>
To process a stream of strings:
</p>
<pre>l := NewLexer(os.Stdin)
for ; token, err := l.Next(); err != nil {
	// process token
}
</pre>
<p>
To access the raw token stream (which includes tokens for comments):
</p>
<pre>  t := NewTokenizer(os.Stdin)
  for ; token, err := t.Next(); err != nil {
	// process token
  }
</pre>

			</div>
		</div>
		

		<div id="pkg-index" class="toggleVisible">
		<div class="collapsed">
			<h2 class="toggleButton" title="Click to show Index section">Index ▹</h2>
		</div>
		<div class="expanded">
			<h2 class="toggleButton" title="Click to hide Index section">Index ▾</h2>

		<!-- Table of contents for API; must be named manual-nav to turn off auto nav. -->
			<div id="manual-nav">
			<dl>
			
			
			
				
				<dd><a href="index.html#Split">func Split(s string) ([]string, error)</a></dd>
			
			
				
				<dd><a href="index.html#Lexer">type Lexer</a></dd>
				
					
					<dd>&nbsp; &nbsp; <a href="index.html#NewLexer">func NewLexer(r io.Reader) *Lexer</a></dd>
				
				
					
					<dd>&nbsp; &nbsp; <a href="index.html#Lexer.Next">func (l *Lexer) Next() (string, error)</a></dd>
				
			
				
				<dd><a href="index.html#Token">type Token</a></dd>
				
				
					
					<dd>&nbsp; &nbsp; <a href="index.html#Token.Equal">func (a *Token) Equal(b *Token) bool</a></dd>
				
			
				
				<dd><a href="index.html#TokenType">type TokenType</a></dd>
				
				
			
				
				<dd><a href="index.html#Tokenizer">type Tokenizer</a></dd>
				
					
					<dd>&nbsp; &nbsp; <a href="index.html#NewTokenizer">func NewTokenizer(r io.Reader) *Tokenizer</a></dd>
				
				
					
					<dd>&nbsp; &nbsp; <a href="index.html#Tokenizer.Next">func (t *Tokenizer) Next() (*Token, error)</a></dd>
				
			
			
			</dl>
			</div><!-- #manual-nav -->

		

		
			<h4>Package files</h4>
			<p>
			<span style="font-size:90%">
			
				<a href="http://localhost:9090/src/github.com/google/shlex/shlex.go">shlex.go</a>
			
			</span>
			</p>
		
		</div><!-- .expanded -->
		</div><!-- #pkg-index -->

		<div id="pkg-callgraph" class="toggle" style="display: none">
		<div class="collapsed">
			<h2 class="toggleButton" title="Click to show Internal Call Graph section">Internal call graph ▹</h2>
		</div> <!-- .expanded -->
		<div class="expanded">
			<h2 class="toggleButton" title="Click to hide Internal Call Graph section">Internal call graph ▾</h2>
			<p>
			  In the call graph viewer below, each node
			  is a function belonging to this package
			  and its children are the functions it
			  calls&mdash;perhaps dynamically.
			</p>
			<p>
			  The root nodes are the entry points of the
			  package: functions that may be called from
			  outside the package.
			  There may be non-exported or anonymous
			  functions among them if they are called
			  dynamically from another package.
			</p>
			<p>
			  Click a node to visit that function's source code.
			  From there you can visit its callers by
			  clicking its declaring <code>func</code>
			  token.
			</p>
			<p>
			  Functions may be omitted if they were
			  determined to be unreachable in the
			  particular programs or tests that were
			  analyzed.
			</p>
			<!-- Zero means show all package entry points. -->
			<ul style="margin-left: 0.5in" id="callgraph-0" class="treeview"></ul>
		</div>
		</div> <!-- #pkg-callgraph -->

		
		
		
			
			
			<h2 id="Split">func <a href="http://localhost:9090/src/github.com/google/shlex/shlex.go?s=9695:9733#L394">Split</a></h2>
			<pre>func Split(s <a href="../../../builtin/index.html#string">string</a>) ([]<a href="../../../builtin/index.html#string">string</a>, <a href="../../../builtin/index.html#error">error</a>)</pre>
			<p>
Split partitions a string into a slice of strings.
</p>

			
			

		
		
			
			
			<h2 id="Lexer">type <a href="http://localhost:9090/src/github.com/google/shlex/shlex.go?s=4115:4135#L132">Lexer</a></h2>
			<pre>type Lexer <a href="index.html#Tokenizer">Tokenizer</a></pre>
			<p>
Lexer turns an input stream into a sequence of tokens. Whitespace and comments are skipped.
</p>


			

			

			
			
			

			
				
				<h3 id="NewLexer">func <a href="http://localhost:9090/src/github.com/google/shlex/shlex.go?s=4191:4224#L135">NewLexer</a></h3>
				<pre>func NewLexer(r <a href="../../../io/index.html">io</a>.<a href="../../../io/index.html#Reader">Reader</a>) *<a href="index.html#Lexer">Lexer</a></pre>
				<p>
NewLexer creates a new lexer from an input stream.
</p>

				
				
			

			
				
				<h3 id="Lexer.Next">func (*Lexer) <a href="http://localhost:9090/src/github.com/google/shlex/shlex.go?s=4366:4404#L142">Next</a></h3>
				<pre>func (l *<a href="index.html#Lexer">Lexer</a>) Next() (<a href="../../../builtin/index.html#string">string</a>, <a href="../../../builtin/index.html#error">error</a>)</pre>
				<p>
Next returns the next word, or an error. If there are no more words,
the error will be io.EOF.
</p>

				
				
				
			
		
			
			
			<h2 id="Token">type <a href="http://localhost:9090/src/github.com/google/shlex/shlex.go?s=1597:1657#L49">Token</a></h2>
			<pre>type Token struct {
    <span class="comment">// contains filtered or unexported fields</span>
}</pre>
			<p>
Token is a (type, value) pair representing a lexographical token.
</p>


			

			

			
			
			

			

			
				
				<h3 id="Token.Equal">func (*Token) <a href="http://localhost:9090/src/github.com/google/shlex/shlex.go?s=1830:1866#L57">Equal</a></h3>
				<pre>func (a *<a href="index.html#Token">Token</a>) Equal(b *<a href="index.html#Token">Token</a>) <a href="../../../builtin/index.html#bool">bool</a></pre>
				<p>
Equal reports whether tokens a, and b, are equal.
Two tokens are equal if both their types and values are equal. A nil token can
never be equal to another token.
</p>

				
				
				
			
		
			
			
			<h2 id="TokenType">type <a href="http://localhost:9090/src/github.com/google/shlex/shlex.go?s=1317:1335#L40">TokenType</a></h2>
			<pre>type TokenType <a href="../../../builtin/index.html#int">int</a></pre>
			<p>
TokenType is a top-level token classification: A word, space, comment, unknown.
</p>


			
				<pre>const (
    <span id="UnknownToken">UnknownToken</span> <a href="index.html#TokenType">TokenType</a> = <a href="../../../builtin/index.html#iota">iota</a>
    <span id="WordToken">WordToken</span>
    <span id="SpaceToken">SpaceToken</span>
    <span id="CommentToken">CommentToken</span>
)</pre>
				<p>
Classes of lexographic token
</p>

			

			

			
			
			

			

			
		
			
			
			<h2 id="Tokenizer">type <a href="http://localhost:9090/src/github.com/google/shlex/shlex.go?s=4762:4840#L160">Tokenizer</a></h2>
			<pre>type Tokenizer struct {
    <span class="comment">// contains filtered or unexported fields</span>
}</pre>
			<p>
Tokenizer turns an input stream into a sequence of typed tokens
</p>


			

			

			
			
			

			
				
				<h3 id="NewTokenizer">func <a href="http://localhost:9090/src/github.com/google/shlex/shlex.go?s=4904:4945#L166">NewTokenizer</a></h3>
				<pre>func NewTokenizer(r <a href="../../../io/index.html">io</a>.<a href="../../../io/index.html#Reader">Reader</a>) *<a href="index.html#Tokenizer">Tokenizer</a></pre>
				<p>
NewTokenizer creates a new tokenizer from an input stream.
</p>

				
				
			

			
				
				<h3 id="Tokenizer.Next">func (*Tokenizer) <a href="http://localhost:9090/src/github.com/google/shlex/shlex.go?s=9570:9612#L389">Next</a></h3>
				<pre>func (t *<a href="index.html#Tokenizer">Tokenizer</a>) Next() (*<a href="index.html#Token">Token</a>, <a href="../../../builtin/index.html#error">error</a>)</pre>
				<p>
Next returns the next token in the stream.
</p>

				
				
				
			
		
	

	







<div id="footer">
Build version go1.6.3.<br>
Except as <a href="https://developers.google.com/site-policies#restrictions">noted</a>,
the content of this page is licensed under the
Creative Commons Attribution 3.0 License,
and code is licensed under a <a href="http://localhost:9090/LICENSE">BSD license</a>.<br>
<a href="http://localhost:9090/doc/tos.html">Terms of Service</a> | 
<a href="http://www.google.com/intl/en/policies/privacy/">Privacy Policy</a>
</div>

</div><!-- .container -->
</div><!-- #page -->

<!-- TODO(adonovan): load these from <head> using "defer" attribute? -->
<script type="text/javascript" src="../../../../lib/godoc/jquery.js"></script>
<script type="text/javascript" src="../../../../lib/godoc/jquery.treeview.js"></script>
<script type="text/javascript" src="../../../../lib/godoc/jquery.treeview.edit.js"></script>


<script type="text/javascript" src="../../../../lib/godoc/godocs.js"></script>

</body>
</html>

